{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db7f3683-b540-4ecb-a37a-cadeac46faed",
   "metadata": {},
   "outputs": [],
   "source": [
    "!unzip drive-download-20241220T223313Z-001.zip -d pdfs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c0fb29-f299-4c08-8ebb-94bafb5b9339",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "print(os.name)  # 'posix' for Linux/Mac, 'nt' for Windows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ddd63e-af00-4469-87c6-c059df0da107",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvcc --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae0798c8-566e-4727-a31a-75bbd5a43ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aaf7aba-65fb-43ea-a110-f2ab22bc398d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pymupdf            # For 'fitz' (PyMuPDF)\n",
    "!pip install pillow             # For 'PIL' (Image)\n",
    "!pip install langchain          # For 'langchain.text_splitter'\n",
    "!pip install transformers       # For 'transformers.AutoTokenizer' and 'transformers.AutoModelForCausalLM'\n",
    "!pip install torch              # For 'torch'         # For 'faiss' (CPU version; use 'faiss-gpu' for GPU sup!port)\n",
    "!pip install numpy   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b822bf3-ca75-48fb-86b1-1af36685bd02",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install faiss-gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a7065f-3e64-44ac-b61a-850fe1ff6a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz  # PyMuPDF\n",
    "from PIL import Image\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "import faiss\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import io\n",
    "\n",
    "# Путь к папке с PDF файлами\n",
    "pdf_folder_path = \"pdfs\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4676fc1-a696-45a0-8c2e-107665fab6dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция для обработки PDF файлов\n",
    "def process_pdfs_from_folder(pdf_folder_path):\n",
    "    all_text, all_images = [], []\n",
    "    pdf_files = glob.glob(os.path.join(pdf_folder_path, \"*.pdf\"))\n",
    "\n",
    "    for pdf_path in pdf_files:\n",
    "        print(f\"Обрабатываем файл: {pdf_path}\")\n",
    "        text, images = [], []\n",
    "\n",
    "        # Открытие и извлечение данных из PDF\n",
    "        with fitz.open(pdf_path) as pdf:\n",
    "            for page in pdf:\n",
    "                text.append(page.get_text())  # Извлекаем текст\n",
    "\n",
    "                # Извлекаем и сохраняем изображения\n",
    "                for img_index, img in enumerate(page.get_images(full=True)):\n",
    "                    xref = img[0]\n",
    "                    base_image = pdf.extract_image(xref)\n",
    "                    image_bytes = base_image[\"image\"]\n",
    "                    image = Image.open(io.BytesIO(image_bytes))\n",
    "                    image_bytes_io = io.BytesIO()\n",
    "                    image.save(image_bytes_io, format=base_image[\"ext\"].upper())\n",
    "                    images.append(image_bytes_io.getvalue())\n",
    "\n",
    "        all_text.append(\" \".join(text))\n",
    "        all_images.extend(images)\n",
    "\n",
    "    return all_text, all_images, pdf_files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b79a122d-e5e9-4c86-8c97-86f4d17b3d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разбиение текста на чанки\n",
    "def split_text_into_chunks(text):\n",
    "    splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=300)\n",
    "    return splitter.split_text(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a73a791-60dc-4d83-9322-91be39948f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81cab91c-f608-44be-a329-c61b82000390",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel, AutoModelForCausalLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d1ca85-ef56-48cc-893e-c9b173712dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from rank_bm25 import BM25Okapi\n",
    "import numpy as np\n",
    "import faiss\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70342436-c09e-4080-a1f5-f39e46d3d47a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_st = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')\n",
    "\n",
    "# Чистка текста\n",
    "def clean_text(text):\n",
    "    text = re.sub(r\"[^а-яА-Яa-zA-Z0-9\\s.,!?]\", \"\", text)\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "    return text\n",
    "\n",
    "def preprocess_chunks(chunks):\n",
    "    cleaned_chunks = [clean_text(chunk) for chunk in chunks]\n",
    "    filtered_chunks = [chunk for chunk in cleaned_chunks if len(chunk.split()) > 5]\n",
    "    return filtered_chunks\n",
    "\n",
    "# Сохранение и загрузка Faiss-индекса\n",
    "def save_embeddings_to_faiss(embeddings):\n",
    "    index = faiss.IndexFlatL2(embeddings.shape[1])\n",
    "    index.add(embeddings)\n",
    "    faiss.write_index(index, \"faiss_index.index\")\n",
    "    return index\n",
    "\n",
    "def load_faiss_index(index_path):\n",
    "    return faiss.read_index(index_path)\n",
    "\n",
    "def get_embeddings_st(texts):\n",
    "    return model_st.encode(texts, show_progress_bar=True)\n",
    "\n",
    "def rank_with_bm25(chunks, query):\n",
    "    tokenized_chunks = [chunk.split() for chunk in chunks]\n",
    "    bm25 = BM25Okapi(tokenized_chunks)\n",
    "    query_tokens = query.split()\n",
    "    scores = bm25.get_scores(query_tokens)\n",
    "    ranked_chunks = sorted(\n",
    "        zip(chunks, scores), key=lambda x: x[1], reverse=True\n",
    "    )\n",
    "    return ranked_chunks\n",
    "\n",
    "def search_similar_chunks_with_images(query, all_chunks, chunk_image_map, index, embeddings, k=5):\n",
    "    \"\"\"\n",
    "    Searches for similar text chunks using Faiss, ranks them with BM25, and retrieves corresponding images.\n",
    "    \"\"\"\n",
    "    # Perform Faiss search\n",
    "    query_embedding = get_embeddings_st([query])[0]\n",
    "    D, I = index.search(np.array([query_embedding]), k=10)  # Retrieve top-10 results from Faiss\n",
    "\n",
    "    # Get text chunks from Faiss results\n",
    "    similar_chunks = [all_chunks[idx] for idx in I[0]]\n",
    "\n",
    "    # Rank the chunks using BM25\n",
    "    ranked_chunks = rank_with_bm25(similar_chunks, query)\n",
    "\n",
    "    # Retrieve top-k chunks and their corresponding images\n",
    "    similar_chunks_with_images = []\n",
    "    for chunk, _ in ranked_chunks[:k]:\n",
    "        idx = all_chunks.index(chunk)  # Find the original index of the chunk\n",
    "        image = chunk_image_map.get(idx)  # Get the associated image\n",
    "        similar_chunks_with_images.append((chunk, image))\n",
    "\n",
    "    return similar_chunks_with_images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b264976e-09f8-4f80-b636-b67decb06ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_images(images):\n",
    "    os.makedirs(\"images\", exist_ok=True)\n",
    "    image_paths = []\n",
    "    for idx, image in enumerate(images):\n",
    "        image_path = os.path.join(\"images\", f\"image_{idx}.png\")\n",
    "        with open(image_path, \"wb\") as f:\n",
    "            f.write(image)\n",
    "        image_paths.append(image_path)\n",
    "    return image_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57260bd0-c5bb-4309-93be-0778e322d85e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_pdfs(pdf_folder_path):\n",
    "    all_text, all_images, pdf_files = process_pdfs_from_folder(pdf_folder_path)\n",
    "    print('1done')\n",
    "    # Разбиение текста на чанки\n",
    "    all_chunks = []\n",
    "    for text in all_text:\n",
    "        all_chunks.extend(split_text_into_chunks(text))\n",
    "    print('2done')\n",
    "    all_chunks = preprocess_chunks(all_chunks)\n",
    "    # Генерация эмбеддингов и сохранение их в Faiss\n",
    "    embeddings = get_embeddings_st(all_chunks)\n",
    "    print('2.1done')\n",
    "    index = save_embeddings_to_faiss(np.array(embeddings))\n",
    "    print('3done')\n",
    "    # Сохранение изображений\n",
    "    image_paths = save_images(all_images)\n",
    "    print('4done')\n",
    "    # Создание отображения чанков и изображений\n",
    "    chunk_image_map = {i: image_paths[i] for i in range(len(all_images))}\n",
    "    print('5done')\n",
    "    # Статистика\n",
    "    print(f\"Обработано {len(pdf_files)} PDF файлов.\")\n",
    "    print(f\"Чанков текста: {len(all_chunks)}.\")\n",
    "    print(f\"Изображений: {len(all_images)}.\")\n",
    "    print(\"Эмбеддинги сохранены в Faiss, изображения в папке 'images'.\")\n",
    "\n",
    "    return all_chunks, chunk_image_map, index, embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36512d9c-bbb6-4704-9c7b-023004161ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -r images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd0d1ef5-69fc-4214-8fb2-d61a6f92352f",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "pdf_folder_path = \"pdfs\"  # Укажите путь к папке с PDF файлами\n",
    "all_chunks, chunk_image_map, index, embeddings = process_pdfs(pdf_folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25623ca7-46e5-4e82-ac0f-d5a58e5512ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"калибровка значений с помощью весов\"\n",
    "similar_chunks_with_images = search_similar_chunks_with_images(query, all_chunks, chunk_image_map, index, embeddings, k=5)\n",
    "\n",
    "print(\"Similar chunks with images:\")\n",
    "for i, (chunk, image) in enumerate(similar_chunks_with_images, start=1):\n",
    "    print(f\"Chunk {i}: {chunk}\")\n",
    "    print(f\"Image: {image}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a96b90-102f-44c2-8a84-f10c34ec59ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba213501-6249-473c-a68f-9f726267cbfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline(\"text-generation\", model=\"MTSAIR/Cotype-Nano\", device=\"cuda\")\n",
    "\n",
    "messages = [\n",
    "\n",
    "  {\"role\": \"system\", \"content\": \"Ты — ИИ-помощник фермера тракториста. Тебе дано задание: необходимо сгенерировать емкий но полный ответ, отвечающий на поставленный вопрос, используя в качестве базы знаний поступающие тебе тексты.\"},\n",
    "\n",
    "  {\"role\": \"user\", \"content\": \"Расскажи мне про ИИ\"},\n",
    "\n",
    "]\n",
    "\n",
    "res = pipe(messages, max_length=1024)\n",
    "\n",
    "print(res[0]['generated_text'][-1]['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9246f254-109e-478a-84b3-07963256d216",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe2 = pipeline(\"text-generation\", model=\"MTSAIR/Cotype-Nano\", device=\"cuda\")\n",
    "messages2 = [\n",
    "  {\"role\": \"system\", \"content\": \"Ты — ИИ-помощник по правильности речи. Проверяй входящие фразы и исправляй грамматичексие, семантические и лексические ошибки, следи за структурой речи. Выведи только исправленную фразу (если она была неправильной, иначе - оставь как есть)\"},\n",
    "  {\"role\": \"user\", \"content\": \"росскажи мене про искуственый интелект\"},\n",
    "]\n",
    "res2 = pipe2(messages2, max_length=1024)\n",
    "print(res2[0]['generated_text'][-1]['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f1ae80d-bff7-4e74-9e10-2504f4ff3e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install 'accelerate>=0.26.0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4429adc5-d739-4ebd-ae28-9ca91a0f32a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Clear all allocated tensors to free memory\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# Optionally force garbage collection (not always necessary)\n",
    "import gc\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d2ad40-51c6-4b8a-ab9b-efbdbd1878be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Check if CUDA is available\n",
    "if torch.cuda.is_available():\n",
    "    # Get the current GPU device\n",
    "    device = torch.cuda.current_device()\n",
    "    print(f\"Device: {torch.cuda.get_device_name(device)}\")\n",
    "    \n",
    "    # Get memory details\n",
    "    total_memory = torch.cuda.get_device_properties(device).total_memory\n",
    "    allocated_memory = torch.cuda.memory_allocated(device)\n",
    "    cached_memory = torch.cuda.memory_reserved(device)\n",
    "    free_memory = total_memory - allocated_memory - cached_memory\n",
    "    \n",
    "    print(f\"Total Memory: {total_memory / 1024**3:.2f} GB\")\n",
    "    print(f\"Allocated Memory: {allocated_memory / 1024**3:.2f} GB\")\n",
    "    print(f\"Cached Memory: {cached_memory / 1024**3:.2f} GB\")\n",
    "    print(f\"Free Memory: {free_memory / 1024**3:.2f} GB\")\n",
    "else:\n",
    "    print(\"CUDA is not available.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c85937e-d964-4a3f-bd6e-3ee5f147cefe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "torch.manual_seed(42)\n",
    "\n",
    "model_name = \"t-tech/T-lite-it-1.0\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name, \n",
    "    torch_dtype=\"auto\",\n",
    ")\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name).to(\"cuda\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b516b4df-2fee-46ac-988f-60e86925e0b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grammar(prompt):\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"Ты — ИИ-помощник по правильности речи. Проверяй входящие фразы и исправляй грамматичексие, семантические и лексические ошибки, следи за структурой речи. Выведи только исправленную фразу (если она была неправильной, иначе - оставь как есть)\"},\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ]\n",
    "    text = tokenizer.apply_chat_template(\n",
    "        messages,\n",
    "        tokenize=False,\n",
    "        add_generation_prompt=True\n",
    "    )\n",
    "    model_inputs = tokenizer([text], return_tensors=\"pt\").to(model.device)\n",
    "    \n",
    "    generated_ids = model.generate(\n",
    "        **model_inputs,\n",
    "        max_new_tokens=256\n",
    "    )\n",
    "    generated_ids = [\n",
    "        output_ids[len(input_ids):] for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)\n",
    "    ]\n",
    "    \n",
    "    response = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "    \n",
    "    return response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e361fb8a-5c3b-4563-83da-748428024a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def helper_agent(similar_chunks, query):\n",
    "    similar_chunks_text = \"\\n\\n\".join(similar_chunks)\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"Ты — ИИ-помощник фермера тракториста. Тебе дано задание: необходимо сгенерировать емкий но полный ответ, отвечающий на поставленный вопрос, используя в качестве базы знаний поступающие тебе тексты.\"},\n",
    "        {\"role\": \"user\", \"content\": f\"Вопрос: {query}\\n\\nТексты для анализа:\\n{similar_chunks_text}\"}\n",
    "    ]\n",
    "    text = tokenizer.apply_chat_template(\n",
    "        messages,\n",
    "        tokenize=False,\n",
    "        add_generation_prompt=True\n",
    "    )\n",
    "    model_inputs = tokenizer([text], return_tensors=\"pt\").to(model.device)\n",
    "    \n",
    "    generated_ids = model.generate(\n",
    "        **model_inputs,\n",
    "        max_new_tokens=4096\n",
    "    )\n",
    "    generated_ids = [\n",
    "        output_ids[len(input_ids):] for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)\n",
    "    ]\n",
    "    \n",
    "    response = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "    \n",
    "    return response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b84c3ed9-638f-4481-bb5e-90ce6f43a2e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ans(question):\n",
    "    # Preprocess the query\n",
    "    query = grammar(question)\n",
    "    \n",
    "    # Search for similar chunks and associated images\n",
    "    similar_chunks_with_images = search_similar_chunks_with_images(\n",
    "        query=query,\n",
    "        all_chunks=all_chunks,\n",
    "        chunk_image_map=chunk_image_map,\n",
    "        index=index,\n",
    "        embeddings=embeddings,\n",
    "        k=5  # Retrieve top-5 results\n",
    "    )\n",
    "    \n",
    "    # Extract chunks (without images) for further processing\n",
    "    similar_chunks = [chunk for chunk, _ in similar_chunks_with_images]\n",
    "    similar_chunks_text = \"\\n\\n\".join(similar_chunks)\n",
    "    \n",
    "    # Pass similar chunks and query to helper_agent for generating response\n",
    "    res = helper_agent(similar_chunks, query)\n",
    "\n",
    "    # Debug the structure of res\n",
    "    print(f\"helper_agent output: {res}\")\n",
    "    \n",
    "    # Since `res` is a string, directly return it\n",
    "    return similar_chunks_with_images, res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05cbc5ea-d12b-4029-a2f0-2d7e14110aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d0de9b-00c6-469b-af5c-e00e7b86968d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0188863b-322d-4414-adba-1e8b788fa8c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "similar_chunks_list = []\n",
    "answers_list = []\n",
    "\n",
    "# Iterate over each row (assuming the question is in a column named 'question')\n",
    "for question in df['user_input']:\n",
    "    similar_chunks, answer = get_ans(question)\n",
    "    similar_chunks_list.append(similar_chunks)  # Append the list directly\n",
    "    answers_list.append(answer)\n",
    "\n",
    "# Add results to new columns in the DataFrame\n",
    "df2['contexts'] = similar_chunks_list  # Store the list directly\n",
    "df2['response'] = answers_list\n",
    "\n",
    "# Save the updated DataFrame back to a new CSV file\n",
    "df2.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ba84c2-85ba-45c8-8575-8c737fe017d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['contexts'] = similar_chunks_list  # Store the list directly\n",
    "df['response'] = answers_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18df9f25-4526-4e6e-bb82-c55943208846",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d535eaab-4a1f-476a-99f4-fce755cee176",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('user_input', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "308f2460-3a4b-4746-a55d-f6d86066330f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d41484c1-712f-470a-8085-63e75f01d48d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting aiogram\n",
      "  Downloading aiogram-3.15.0-py3-none-any.whl.metadata (7.5 kB)\n",
      "Collecting aiofiles<24.2,>=23.2.1 (from aiogram)\n",
      "  Downloading aiofiles-24.1.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting aiohttp<3.11,>=3.9.0 (from aiogram)\n",
      "  Downloading aiohttp-3.10.11-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
      "Requirement already satisfied: certifi>=2023.7.22 in /opt/conda/lib/python3.10/site-packages (from aiogram) (2024.8.30)\n",
      "Collecting magic-filter<1.1,>=1.0.12 (from aiogram)\n",
      "  Downloading magic_filter-1.0.12-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting pydantic<2.10,>=2.4.1 (from aiogram)\n",
      "  Downloading pydantic-2.9.2-py3-none-any.whl.metadata (149 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.4/149.4 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions<=5.0,>=4.7.0 in /opt/conda/lib/python3.10/site-packages (from aiogram) (4.12.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<3.11,>=3.9.0->aiogram) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp<3.11,>=3.9.0->aiogram) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<3.11,>=3.9.0->aiogram) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp<3.11,>=3.9.0->aiogram) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp<3.11,>=3.9.0->aiogram) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<3.11,>=3.9.0->aiogram) (1.18.3)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<3.11,>=3.9.0->aiogram) (4.0.3)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/conda/lib/python3.10/site-packages (from pydantic<2.10,>=2.4.1->aiogram) (0.6.0)\n",
      "Collecting pydantic-core==2.23.4 (from pydantic<2.10,>=2.4.1->aiogram)\n",
      "  Downloading pydantic_core-2.23.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: idna>=2.0 in /opt/conda/lib/python3.10/site-packages (from yarl<2.0,>=1.12.0->aiohttp<3.11,>=3.9.0->aiogram) (3.7)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /opt/conda/lib/python3.10/site-packages (from yarl<2.0,>=1.12.0->aiohttp<3.11,>=3.9.0->aiogram) (0.2.1)\n",
      "Downloading aiogram-3.15.0-py3-none-any.whl (603 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m603.9/603.9 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading aiofiles-24.1.0-py3-none-any.whl (15 kB)\n",
      "Downloading aiohttp-3.10.11-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m23.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "Downloading magic_filter-1.0.12-py3-none-any.whl (11 kB)\n",
      "Downloading pydantic-2.9.2-py3-none-any.whl (434 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m434.9/434.9 kB\u001b[0m \u001b[31m39.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pydantic_core-2.23.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m33.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "Installing collected packages: pydantic-core, magic-filter, aiofiles, pydantic, aiohttp, aiogram\n",
      "  Attempting uninstall: pydantic-core\n",
      "    Found existing installation: pydantic_core 2.27.1\n",
      "    Uninstalling pydantic_core-2.27.1:\n",
      "      Successfully uninstalled pydantic_core-2.27.1\n",
      "  Attempting uninstall: pydantic\n",
      "    Found existing installation: pydantic 2.10.3\n",
      "    Uninstalling pydantic-2.10.3:\n",
      "      Successfully uninstalled pydantic-2.10.3\n",
      "  Attempting uninstall: aiohttp\n",
      "    Found existing installation: aiohttp 3.11.11\n",
      "    Uninstalling aiohttp-3.11.11:\n",
      "      Successfully uninstalled aiohttp-3.11.11\n",
      "Successfully installed aiofiles-24.1.0 aiogram-3.15.0 aiohttp-3.10.11 magic-filter-1.0.12 pydantic-2.9.2 pydantic-core-2.23.4\n"
     ]
    }
   ],
   "source": [
    "!pip install aiogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e34ab68-2cc0-4756-825c-28d698116079",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:aiogram.dispatcher:Start polling\n",
      "INFO:aiogram.dispatcher:Run polling for bot @vid_prof_agro_bot id=7847179564 - 'VID_ProfAgro_Bot'\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7075cdc1fce469d9f061854308ea0de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "helper_agent output: Для проверки предоставленного текста и ответа на ваш вопрос о лакокрасочном покрытии для распределителей удобрений, давайте разберем ключевые моменты.\n",
      "\n",
      "### Анализ текста:\n",
      "\n",
      "1. **Технология лакирования**:\n",
      "   - Применяется комбинированная технология, включающая катодное погружное лакирование (KTL) и метод порошкового напыления.\n",
      "   - KTL используется для грунтования, обеспечивая защиту от коррозии.\n",
      "   - Порошковое напыление обеспечивает высококачественный внешний вид и чрезвычайно плотный слой краски для защиты от механических воздействий.\n",
      "\n",
      "2. **Преимущества**:\n",
      "   - Высококачественное многослойное лакирование обеспечивает двойную защиту от механических воздействий и коррозии.\n",
      "   - Процесс включает 14 этапов подготовки к лакированию, что гарантирует надежную защиту.\n",
      "\n",
      "3. **Определение коэффициента калибровки**:\n",
      "   - Для точного внесения удобрений используется система калибровки, которая включает в себя определение коэффициента калибровки через боковое устройство определения нормы внесения.\n",
      "   - Необходимо выполнить пробный запуск без меню калибровки перед началом калибровки.\n",
      "   - Калибровка позволяет оптимизировать систему подачи удобрений и улучшить точность внесения.\n",
      "\n",
      "### Ответ на вопрос:\n",
      "\n",
      "Лакокрасочное покрытие для распределителей удобрений, используемое в модели ZAV, ZATS и ZGTS с 2022 года, сочетает в себе катодное погружное лакирование (KTL) и порошковое напыление. Это обеспечивает высококачественную защиту от коррозии и механических воздействий. Особое внимание уделяется процессу калибровки, который помогает точно определить норму внесения удобрений, улучшая их равномерное распределение на поле.\n",
      "\n",
      "### Вывод:\n",
      "\n",
      "Предоставленный текст описывает современные технологии лакирования и калибровки для распределителей удобрений, которые обеспечивают надежную защиту оборудования и точное внесение удобрений. Если ваш вопрос касался именно технологии лакирования, то вышеизложенный анализ дает полное представление о применяемых методах и их преимуществах. Если же вопрос был о чем-то другом, пожалуйста, уточните, и я предоставлю более специализированный ответ.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2372cb62dd20434ea4c4c1a5954360b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "helper_agent output: Если у вас возникли проблемы с трактором, важно учитывать несколько ключевых аспектов безопасности и эксплуатации:\n",
      "\n",
      "1. **Фиксация трактора и агрегата**: Перед началом работы или устранением неисправностей всегда зафиксируйте трактор и агрегат от непреднамеренного пуска и откатывания. Это предотвратит аварийные ситуации, такие как захватывание или наматывание открытым первичным валом входного редуктора.\n",
      "\n",
      "2. **Карданный вал и защитные приспособления**: Используйте только те карданные валы, которые указаны в списке допустимых. Убедитесь, что на карданном валу установлены все защитные приспособления и они работоспособны. Никогда не используйте карданный вал без защитных приспособлений или с поврежденными защитными приспособлениями.\n",
      "\n",
      "3. **Безопасность при работе с двигателем**: Не поднимайтесь на погрузочную платформу, пока двигатель трактора работает, особенно если карданный вал подключен. Также никогда не открывайте и не снимайте защитные приспособления с движущихся частей агрегата, пока работает двигатель.\n",
      "\n",
      "4. **Работа с электрооборудованием**: Будьте осторожны с электрическими линиями и избегайте контакта с ними. Это может привести к серьезным травмам или ожогам.\n",
      "\n",
      "5. **Опасности от движущихся частей**: Держитесь на безопасном расстоянии от агрегата, пока он работает, чтобы избежать ударов или разбрасываемых материалов. Не засовывайте руки в опасные зоны.\n",
      "\n",
      "6. **Погрузка и выгрузка**: Перед погрузкой или выгрузкой агрегата убедитесь, что он надлежащим образом присоединен к трактору. Используйте обозначенные точки для строповки подъемных ремней и следите за их прочностью.\n",
      "\n",
      "7. **Условия движения**: При управлении трактором с навешенными агрегатами учитывайте личные способности, состояние дороги, погодные условия и другие факторы, которые могут повлиять на управляемость.\n",
      "\n",
      "8. **Общие меры предосторожности**: Всегда следуйте инструкциям по технике безопасности, указанным в руководстве пользователя, и не пренебрегайте мерами предосторожности для предотвращения травм и аварий.\n",
      "\n",
      "Если ваша проблема связана с конкретной неисправностью, например, с карданным валом или двигателем, рекомендую обратить внимание на следующее:\n",
      "\n",
      "- Проверьте, нет ли механических повреждений на карданном валу.\n",
      "- Убедитесь, что все защитные приспособления на месте и исправны.\n",
      "- Проверьте давление в пневматической тормозной системе перед началом движения.\n",
      "- При необходимости обратитесь к специалисту для диагностики и ремонта.\n",
      "\n",
      "Эти меры помогут вам безопасно и эффективно решить любые проблемы с трактором и его агрегатами.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c25bdf804acd4fa4918242bc7e233336",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "helper_agent output: Для улучшения текстов и их структуры, необходимо выполнить несколько шагов:\n",
      "\n",
      "1. **Устранение повторов и несоответствий:**\n",
      "   - В текстах есть повторяющиеся фразы, такие как \"чтобы быть уверенным в успехе\" и \"достижение этого является целью настоящей инструкции по эксплуатации\". Это можно устранить путем переформулировки.\n",
      "   - Также заметны несоответствия в идентификационных данных и описаниях изделий (например, различия в номерах и годах выпуска).\n",
      "\n",
      "2. **Структурирование информации:**\n",
      "   - Разделите текст на логические блоки, например, разделы по эксплуатации, техническому обслуживанию и безопасности.\n",
      "   - Используйте заголовки и подзаголовки для лучшей читаемости.\n",
      "\n",
      "3. **Исправление ошибок и неточностей:**\n",
      "   - Исправьте опечатки и неточности, такие как \"LeipzigPlagwitz\" вместо \"ЛейпцигПлагвитц\".\n",
      "   - Убедитесь, что все идентификационные данные согласованы и точны.\n",
      "\n",
      "4. **Создание более четких инструкций:**\n",
      "   - Для каждого действия или процедуры предоставьте четкие и последовательные инструкции.\n",
      "   - Пример: \"Чтобы изменить расстояние между колеями, активируйте Ручной ввод.\" можно улучшить до \"Для корректировки расстояния между колеями, перейдите в режим Ручной ввод.\"\n",
      "\n",
      "5. **Обобщение и упрощение:**\n",
      "   - Упростите сложные предложения, чтобы сделать их более доступными для понимания.\n",
      "   - Например, \"Причинить ущерб не только себе, но также совершить ошибки, которые будут касаться не его, но будут причиной неудач с техникой\" можно переформулировать как \"Неправильное использование техники может привести к ошибкам и повреждению оборудования.\"\n",
      "\n",
      "### Пример исправленного текста:\n",
      "\n",
      "**Раздел 1: Общие указания**\n",
      "\n",
      "- **Бережное отношение к оборудованию:** Обязанность бережного отношения и осторожных действий для обеспечения надлежащего обращения с агрегатом. Несоблюдение указаний может привести к поломкам оборудования.\n",
      "\n",
      "**Раздел 2: Эксплуатация и техническое обслуживание**\n",
      "\n",
      "- **Эксплуатация:** Ознакомьтесь с назначением каждого приспособления машины и получите навыки в обслуживании. Это обеспечит удовлетворенность работой и машиной.\n",
      "- **Техническое обслуживание:** Выполняйте работы по техническому обслуживанию и контролю точно в срок. Защитите рабочую среду от непреднамеренного ввода в эксплуатацию.\n",
      "\n",
      "**Раздел 3: Безопасность**\n",
      "\n",
      "- **Инструктаж:** При инструктаже операторов ознакомьте их с мерами безопасности. Подробные указания содержатся в соответствующих главах руководства.\n",
      "- **Изменения в конструкции:** Без разрешения производителя запрещается вносить изменения или дополнения в конструкцию агрегата.\n",
      "\n",
      "**Раздел 4: Идентификационные данные**\n",
      "\n",
      "- **Описание изделия:** ISOBUS TS BAG0204.8 01.24 9 3. Проверьте идентификационные данные на фирменной табличке. Основные параметры: тип, год выпуска, масса, адрес изготовителя.\n",
      "\n",
      "**Примеры конкретных процедур:**\n",
      "\n",
      "1. **Изменение расстояния между колеями:**\n",
      "   - Перейдите в режим Ручной ввод.\n",
      "   - Введите требуемое расстояние или перекрытие колеи.\n",
      "\n",
      "2. **Настройка чувствительности световой полосы:**\n",
      "   - Установите ширину линии колеи вручную.\n",
      "   - Убедитесь, что световая полоса отображает отклонение от линии колеи.\n",
      "\n",
      "3. **Профилактическое обслуживание:**\n",
      "   - Закрепите и зафиксируйте большие узлы на подъемных приспособлениях.\n",
      "   - Проверьте крепление резьбовых соединений и подтяните их при необходимости.\n",
      "\n",
      "Таким образом, тексты становятся более структурированными, понятными и менее загроможденными.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45ef97f803854ffdbe6b0d0767d16e69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:aiogram.event:Update id=716731306 is not handled. Duration 126090 ms by bot id=7847179564\n",
      "ERROR:aiogram.event:Cause exception while process update id=716731306 by bot id=7847179564\n",
      "TelegramNetworkError: HTTP Client says - Request timeout error\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/aiohttp/client.py\", line 663, in _request\n",
      "    conn = await self._connector.connect(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/aiohttp/connector.py\", line 538, in connect\n",
      "    proto = await self._create_connection(req, traces, timeout)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/aiohttp/connector.py\", line 1050, in _create_connection\n",
      "    _, proto = await self._create_direct_connection(req, traces, timeout)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/aiohttp/connector.py\", line 1353, in _create_direct_connection\n",
      "    transp, proto = await self._wrap_create_connection(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/aiohttp/connector.py\", line 1116, in _wrap_create_connection\n",
      "    return await self._loop.create_connection(*args, **kwargs, sock=sock)\n",
      "  File \"/opt/conda/lib/python3.10/asyncio/base_events.py\", line 1103, in create_connection\n",
      "    transport, protocol = await self._create_connection_transport(\n",
      "  File \"/opt/conda/lib/python3.10/asyncio/base_events.py\", line 1133, in _create_connection_transport\n",
      "    await waiter\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/aiogram/client/session/aiohttp.py\", line 181, in make_request\n",
      "    async with session.post(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/aiohttp/client.py\", line 1360, in __aenter__\n",
      "    self._resp: _RetType = await self._coro\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/aiohttp/client.py\", line 578, in _request\n",
      "    with timer:\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/aiohttp/helpers.py\", line 749, in __exit__\n",
      "    raise asyncio.TimeoutError from exc_val\n",
      "asyncio.exceptions.TimeoutError\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/aiogram/dispatcher/dispatcher.py\", line 309, in _process_update\n",
      "    response = await self.feed_update(bot, update, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/aiogram/dispatcher/dispatcher.py\", line 158, in feed_update\n",
      "    response = await self.update.wrap_outer_middleware(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/aiogram/dispatcher/middlewares/error.py\", line 25, in __call__\n",
      "    return await handler(event, data)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/aiogram/dispatcher/middlewares/user_context.py\", line 56, in __call__\n",
      "    return await handler(event, data)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/aiogram/fsm/middleware.py\", line 42, in __call__\n",
      "    return await handler(event, data)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/aiogram/dispatcher/event/telegram.py\", line 121, in trigger\n",
      "    return await wrapped_inner(event, kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/aiogram/dispatcher/event/handler.py\", line 43, in call\n",
      "    return await wrapped()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/aiogram/dispatcher/dispatcher.py\", line 276, in _listen_update\n",
      "    return await self.propagate_event(update_type=update_type, event=event, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/aiogram/dispatcher/router.py\", line 146, in propagate_event\n",
      "    return await observer.wrap_outer_middleware(_wrapped, event=event, data=kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/aiogram/dispatcher/router.py\", line 141, in _wrapped\n",
      "    return await self._propagate_event(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/aiogram/dispatcher/router.py\", line 174, in _propagate_event\n",
      "    response = await router.propagate_event(update_type=update_type, event=event, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/aiogram/dispatcher/router.py\", line 146, in propagate_event\n",
      "    return await observer.wrap_outer_middleware(_wrapped, event=event, data=kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/aiogram/dispatcher/router.py\", line 141, in _wrapped\n",
      "    return await self._propagate_event(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/aiogram/dispatcher/router.py\", line 166, in _propagate_event\n",
      "    response = await observer.trigger(event, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/aiogram/dispatcher/event/telegram.py\", line 121, in trigger\n",
      "    return await wrapped_inner(event, kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/aiogram/dispatcher/event/handler.py\", line 43, in call\n",
      "    return await wrapped()\n",
      "  File \"/tmp/ipykernel_3616/1194678184.py\", line 24, in handle_message\n",
      "    await message.answer(res_text)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/aiogram/methods/base.py\", line 84, in emit\n",
      "    return await bot(self)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/aiogram/client/bot.py\", line 494, in __call__\n",
      "    return await self.session(self, method, timeout=request_timeout)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/aiogram/client/session/base.py\", line 254, in __call__\n",
      "    return cast(TelegramType, await middleware(bot, method))\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/aiogram/client/session/aiohttp.py\", line 186, in make_request\n",
      "    raise TelegramNetworkError(method=method, message=\"Request timeout error\")\n",
      "aiogram.exceptions.TelegramNetworkError: HTTP Client says - Request timeout error\n",
      "INFO:aiogram.event:Update id=716731307 is not handled. Duration 126094 ms by bot id=7847179564\n",
      "ERROR:aiogram.event:Cause exception while process update id=716731307 by bot id=7847179564\n",
      "TelegramNetworkError: HTTP Client says - Request timeout error\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/aiohttp/client.py\", line 663, in _request\n",
      "    conn = await self._connector.connect(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/aiohttp/connector.py\", line 538, in connect\n",
      "    proto = await self._create_connection(req, traces, timeout)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/aiohttp/connector.py\", line 1050, in _create_connection\n",
      "    _, proto = await self._create_direct_connection(req, traces, timeout)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/aiohttp/connector.py\", line 1353, in _create_direct_connection\n",
      "    transp, proto = await self._wrap_create_connection(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/aiohttp/connector.py\", line 1116, in _wrap_create_connection\n",
      "    return await self._loop.create_connection(*args, **kwargs, sock=sock)\n",
      "  File \"/opt/conda/lib/python3.10/asyncio/base_events.py\", line 1103, in create_connection\n",
      "    transport, protocol = await self._create_connection_transport(\n",
      "  File \"/opt/conda/lib/python3.10/asyncio/base_events.py\", line 1133, in _create_connection_transport\n",
      "    await waiter\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/aiogram/client/session/aiohttp.py\", line 181, in make_request\n",
      "    async with session.post(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/aiohttp/client.py\", line 1360, in __aenter__\n",
      "    self._resp: _RetType = await self._coro\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/aiohttp/client.py\", line 578, in _request\n",
      "    with timer:\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/aiohttp/helpers.py\", line 749, in __exit__\n",
      "    raise asyncio.TimeoutError from exc_val\n",
      "asyncio.exceptions.TimeoutError\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/aiogram/dispatcher/dispatcher.py\", line 309, in _process_update\n",
      "    response = await self.feed_update(bot, update, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/aiogram/dispatcher/dispatcher.py\", line 158, in feed_update\n",
      "    response = await self.update.wrap_outer_middleware(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/aiogram/dispatcher/middlewares/error.py\", line 25, in __call__\n",
      "    return await handler(event, data)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/aiogram/dispatcher/middlewares/user_context.py\", line 56, in __call__\n",
      "    return await handler(event, data)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/aiogram/fsm/middleware.py\", line 42, in __call__\n",
      "    return await handler(event, data)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/aiogram/dispatcher/event/telegram.py\", line 121, in trigger\n",
      "    return await wrapped_inner(event, kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/aiogram/dispatcher/event/handler.py\", line 43, in call\n",
      "    return await wrapped()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/aiogram/dispatcher/dispatcher.py\", line 276, in _listen_update\n",
      "    return await self.propagate_event(update_type=update_type, event=event, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/aiogram/dispatcher/router.py\", line 146, in propagate_event\n",
      "    return await observer.wrap_outer_middleware(_wrapped, event=event, data=kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/aiogram/dispatcher/router.py\", line 141, in _wrapped\n",
      "    return await self._propagate_event(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/aiogram/dispatcher/router.py\", line 174, in _propagate_event\n",
      "    response = await router.propagate_event(update_type=update_type, event=event, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/aiogram/dispatcher/router.py\", line 146, in propagate_event\n",
      "    return await observer.wrap_outer_middleware(_wrapped, event=event, data=kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/aiogram/dispatcher/router.py\", line 141, in _wrapped\n",
      "    return await self._propagate_event(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/aiogram/dispatcher/router.py\", line 166, in _propagate_event\n",
      "    response = await observer.trigger(event, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/aiogram/dispatcher/event/telegram.py\", line 121, in trigger\n",
      "    return await wrapped_inner(event, kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/aiogram/dispatcher/event/handler.py\", line 43, in call\n",
      "    return await wrapped()\n",
      "  File \"/tmp/ipykernel_3616/1194678184.py\", line 24, in handle_message\n",
      "    await message.answer(res_text)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/aiogram/methods/base.py\", line 84, in emit\n",
      "    return await bot(self)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/aiogram/client/bot.py\", line 494, in __call__\n",
      "    return await self.session(self, method, timeout=request_timeout)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/aiogram/client/session/base.py\", line 254, in __call__\n",
      "    return cast(TelegramType, await middleware(bot, method))\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/aiogram/client/session/aiohttp.py\", line 186, in make_request\n",
      "    raise TelegramNetworkError(method=method, message=\"Request timeout error\")\n",
      "aiogram.exceptions.TelegramNetworkError: HTTP Client says - Request timeout error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "helper_agent output: Чтобы помочь вам в эксплуатации агрегата AMAZONE, важно следовать нескольким ключевым рекомендациям:\n",
      "\n",
      "1. **Прочтение руководства по эксплуатации**: Перед началом работы обязательно ознакомьтесь с руководством по эксплуатации, которое включает в себя инструкции по использованию и обслуживанию агрегата. Это поможет избежать ошибок и повысит эффективность работы.\n",
      "\n",
      "2. **Регулярное техническое обслуживание**: Проводите регулярное обслуживание агрегата, включая замену изношенных или поврежденных деталей. Это увеличит срок службы оборудования и обеспечит его надежную работу.\n",
      "\n",
      "3. **Обновление руководств**: Наши руководства по эксплуатации регулярно обновляются на основе отзывов пользователей. Если у вас есть предложения или вопросы, пожалуйста, сообщите нам, чтобы мы могли улучшить руководства.\n",
      "\n",
      "4. **Проверка гидравлических шлангопроводов**: При подключении гидравлических шлангопроводов убедитесь, что гидросистемы трактора и агрегата не находятся под давлением. Регулярно проверяйте шлангопроводы на наличие повреждений и загрязнений, и при необходимости заменяйте их.\n",
      "\n",
      "5. **Правильная затяжка винтов**: Используйте указанные моменты затяжки винтов (1 - 2,5 Нм; 2 - 7 Нм), чтобы обеспечить надежность соединений.\n",
      "\n",
      "6. **Очистка и замена фильтров**: Очистка фильтров трубопровода сжатого воздуха в тормозной линии и замена фильтров по мере необходимости обеспечат корректную работу системы торможения.\n",
      "\n",
      "7. **Настройка стояночного тормоза**: При необходимости отрегулируйте стояночный тормоз, чтобы обеспечить его корректную работу и безопасность.\n",
      "\n",
      "8. **Калибровка и настройка оборудования**: Используйте функции калибровки и настройки, такие как \"Метод калибровки на поле\" и \"Настройка ArgusTwin\", чтобы оптимизировать работу агрегата.\n",
      "\n",
      "9. **Обращение за помощью**: Если у вас возникают вопросы или проблемы, свяжитесь с партнером по сервису в вашем регионе. Они смогут предоставить дополнительную помощь и консультацию.\n",
      "\n",
      "Следуя этим рекомендациям, вы сможете эффективно эксплуатировать агрегат AMAZONE и обеспечить его долгий срок службы. Если у вас есть конкретные вопросы или проблемы, пожалуйста, уточните их, и я постараюсь помочь вам более подробно.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83dd036da3e84ed5997e2770de1f8850",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:aiogram.event:Update id=716731309 is handled. Duration 83146 ms by bot id=7847179564\n",
      "INFO:aiogram.event:Update id=716731310 is handled. Duration 13922 ms by bot id=7847179564\n",
      "INFO:aiogram.event:Update id=716731308 is handled. Duration 83229 ms by bot id=7847179564\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "helper_agent output: Исходя из предоставленных текстов, информация о цвете трактора напрямую не связана с его функциональными характеристиками или техническими особенностями. Однако, в одном из текстов упоминается, что трактор имеет \"синий\" блок управления (подъем двойного действия) и \"красный\" напорный маслопровод системы LoadSensing. Это описание относится к цветовой маркировке элементов управления и систем трактора, а не к его внешнему цвету.\n",
      "\n",
      "Что касается вашего вопроса: \"Трактор был синим, а не красным\", то в контексте этих текстов нет прямой информации о цвете самого трактора. Тексты описывают цвета различных элементов и систем трактора, таких как блок управления и маслопроводы, но не содержат данных о цвете самого корпуса трактора.\n",
      "\n",
      "Если ваш вопрос касается конкретно цвета трактора, то, основываясь на предоставленной информации, мы можем сделать вывод, что цвет трактора не указан и не имеет отношения к его функциональным особенностям. Если же вам нужна информация о цвете трактора, возможно, стоит обратиться к другим источникам или документации, где может быть указана эта информация. \n",
      "\n",
      "Если же вопрос касается чего-то другого, пожалуйста, уточните, и я постараюсь помочь более точно.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5dd89bc21e9442280d46900d83fa7a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from aiogram import Bot, Dispatcher, Router\n",
    "from aiogram.types import Message\n",
    "from aiogram import F\n",
    "import asyncio\n",
    "import logging\n",
    "\n",
    "# Включаем логирование\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "# Укажите токен вашего бота\n",
    "API_TOKEN = \"7847179564:AAGWg7KkW23DxoPgPN5KtgnFyPNy-kXpnuQ\"\n",
    "\n",
    "# Инициализация бота и диспетчера\n",
    "bot = Bot(token=API_TOKEN)\n",
    "router = Router()\n",
    "dp = Dispatcher()\n",
    "dp.include_router(router)\n",
    "\n",
    "@router.message(F.text)\n",
    "async def handle_message(message: Message):\n",
    "    # Преобразуем текст в нижний регистр\n",
    "    _, res_text = get_ans(message.text)\n",
    "    # Отправляем преобразованный текст пользователю\n",
    "    await message.answer(res_text)\n",
    "\n",
    "async def start():\n",
    "    # Запуск бота\n",
    "    await dp.start_polling(bot)\n",
    "\n",
    "await start()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab3a5c51-5905-47f8-bacc-672880c3ad46",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
